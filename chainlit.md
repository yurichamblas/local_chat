## ğŸ§  Local Chat con Qwen3 y acceso local ğŸ”ğŸ“‚

Â¡Bienvenido a tu asistente local con capacidades LLM! Este entorno usa **Chainlit** como interfaz conversacional y un modelo **Qwen3:8b** ejecutado localmente mediante **Ollama**, con soporte para explorar y procesar archivos directamente desde tu sistema.

### ğŸš€ Â¿QuÃ© puede hacer Local Chat?

- ğŸ“ **Listar carpetas**: Muestra el contenido de directorios locales permitidos.
- ğŸ“„ **Leer archivos**: Visualiza archivos `.txt`, `.md`, `.py`, `.json`, `.pdf`, `.docx`, `.xlsx` y mÃ¡s.
- ğŸ” **Buscar texto**: Busca una palabra o frase dentro de mÃºltiples archivos en una carpeta.
- ğŸ“ **Resumir documentos**: Usa LLMs para generar resÃºmenes breves de archivos individuales o carpetas completas.

### ğŸ› ï¸ TecnologÃ­as utilizadas

- ğŸ§  **Modelo:** `qwen3:8b` (Ollama)
- ğŸ’¬ **Interfaz:** `Chainlit`
- ğŸ§° **Frameworks:** `LangChain`, `LangChain-Ollama`
- ğŸ—‚ï¸ **ExploraciÃ³n local:** IntegraciÃ³n segura y restringida con el sistema de archivos


Â¡Explora tus datos con IA local, sin depender de la nube! â˜ï¸âŒ  
